## Misinformation and biases

- Misinformation and biases may present within [[pre-training]] data and may inadvertently be amplified
- Manifest as imitative falsehood and the reinforcement of societal biases

## Knowledge boundary

- The inability of [[Large Language Models|LLMs]] to memorize all factual knowledge encountered during [[pre-training]], especially the less frequent long-tail knowledge
- The intrinsic boundary of the [[pre-training]] data itself, which does not include rapidly evolving world knowledge or content restricted by copyright laws

## Inferior alignment data

- LLMs struggle to acquire new knowledge in [[fine-tuning]] effectively
- There is a correlation between the acquisition of new knowledge through [[fine-tuning]] and increased hallucinations
