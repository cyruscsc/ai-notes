## Data filtering

- Select high-quality [[pre-training]] data from reliable sources carefully
- Ensure the factual correctness of data while also minimizing the introduction of social biases

## Model editing

- Inject up-to-date knowledge by editing model’s parameters
- Rectify model behaviour by incorporating additional knowledge

### Locate-then-edit

- First locate the "buggy" part of the model parameters
- Then apply an update to them to alter the model’s behaviour

### Meta-learning

- Train an external hyper-network to predict the weight update of the original model
- Often require additional training and memory cost

## Retrieval augmented generation

- Leverage external non-parametric database for knowledge supplying
- First retrieve relevant knowledge from external sources by a retriever
- Then the final response is generated by a generator conditioning on both user query and retrieved documents

### One-time retrieval

- Directly prepend the external knowledge obtained from a single [[retrieval]] to the [[Large Language Models|LLMs]]’ prompt
- May fall short when confronted with intricate challenges like multi-step reasoning and long-form question answering

### Iterative retrieval

- Allow for continuously gathering knowledge throughout the [[generation]] process
- Incorporate external knowledge at each reasoning step and further guide [[retrieval]] process based on ongoing reasoning for chain-of-thought prompting, reducing factual errors in reasoning chains
- See [[Iterative Retrieval]]

### Post-hoc retrieval

- Research relevant evidence and subsequently revise the initial generation based on detected discrepancies with the evidence
- May generate verifying questions and then refines the rationales based on retrieved knowledge, ensuring a more factual response
- May sample various potential answers, allowing for a more comprehensive [[retrieval]] feedback