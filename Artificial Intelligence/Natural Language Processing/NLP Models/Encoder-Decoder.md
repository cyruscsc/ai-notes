## Characteristics

- Effective for sequence-to-sequence (seq2seq) tasks, where the input and output are sequences of variable lengths
- Often used for machine translation, text summarization, and question answering

## Components

### Encoder

- Processes the input sequence and converts it into a fixed-length context vector or intermediate representation
	- E.g. [[distributed representation]]
- Captures the semantic and syntactic information of the input sequence
- Typically implemented with [[Recurrent Neural Networks|RNNs]], LSTMs, GRUs, or [[Transformers]]

### Decoder

- Takes the context vector generated by the encoder and produces the output sequence
- Predicts one token at a time, using both the context vector and its own previous outputs as inputs
- Typically implemented with [[Recurrent Neural Networks|RNNs]], LSTMs, GRUs, or [[Transformers]]

## Approach

### Encoding

- The input sequence is [[Tokenization|tokenized]] and passed through the encoder
- The encoder generates hidden states that summarize the input’s information

### Decoding

- The decoder generates the output sequence one token at a time, conditioned on the context vector and previously generated tokens
- The encoder also generates hidden states

## Challenges

- Can be challenging for large input sequences to store all that information into a single state value
- Some of the hidden states in the input sequence are more important than others
- [[Attention]] allows the decoder to focus on specific parts of the input sequence dynamically

## RNNs implementation

```plaintext
                          decoder
                    ┌─┐       ┌─┐
                    │O│       │O│
                    └─┘       └─┘
                     ↑         ↑
┌─┐  ┌─┐  ┌─┐  ┌─┐  ┌─┐  ┌─┐  ┌─┐
│N│─→│S│─→│N│─→│S│─→│N│─→│S│─→│N│
└─┘  └─┘  └─┘  └─┘  └─┘  └─┘  └─┘
 ↑         ↑         
┌─┐       ┌─┐
│I│       │I│
└─┘       └─┘
encoder
```

> `I`: input word
> `N`: neural network
> `S`: hidden state
> `O`: output word

## Transformers implementation

- See [[Transformers#Implementation|Transformers]]